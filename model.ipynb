{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import Input, regularizers, Sequential, optimizers, preprocessing, initializers\n",
    "from tensorflow.keras.activations import relu, tanh\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Dense, BatchNormalization, Dropout, Flatten, InputLayer, Conv2D, Activation\n",
    "from tensorflow import config\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"GPU is\", \"available\" if config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.path.join(\"dataset\", \"data_augmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(filters, learning_rate=0.2, activation=\"relu\", input_shape=(400, 400, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters[0],  kernel_size = (5, 5), input_shape=input_shape, \n",
    "                     kernel_initializer=initializers.GlorotNormal(), padding=\"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation)) \n",
    "    \n",
    "    for index, filter_ in enumerate(filters[1:-2]):\n",
    "        model.add(Conv2D(filter_, kernel_size = (3, 3), activation=activation, padding=\"same\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(activation)) \n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(filters[-2]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))  \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(filters[-1]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation)) \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(4, activation = 'softmax'))\n",
    "    \n",
    "    opt = optimizers.Adam(learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt,\n",
    "                 metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator(Sequence) :\n",
    "  \n",
    "        def __init__(self, x_set, y_set, batch_size):\n",
    "            self.x, self.y = x_set, y_set\n",
    "            self.batch_size = batch_size\n",
    "\n",
    "        def __len__(self):\n",
    "            return ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "            return np.array([StandardScaler().fit_transform(io.imread(os.path.join(PATH, file_name))).reshape((400, 400, 1))             \n",
    "                   for file_name in batch_x]), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PROESTRO_535_1_0_1_fliped.jpg</td>\n",
       "      <td>PROESTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESTRO_227_2_90_2_fliped.jpg</td>\n",
       "      <td>ESTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METAESTRO_153_3_90_0_fliped.jpg</td>\n",
       "      <td>METAESTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DIESTRO_603_4_90_0_fliped.jpg</td>\n",
       "      <td>DIESTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTRO_547_2_0_1_fliped.jpg</td>\n",
       "      <td>ESTRO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filename      label\n",
       "0    PROESTRO_535_1_0_1_fliped.jpg   PROESTRO\n",
       "1      ESTRO_227_2_90_2_fliped.jpg      ESTRO\n",
       "2  METAESTRO_153_3_90_0_fliped.jpg  METAESTRO\n",
       "3    DIESTRO_603_4_90_0_fliped.jpg    DIESTRO\n",
       "4       ESTRO_547_2_0_1_fliped.jpg      ESTRO"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/name_data_augmented.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.filename.values\n",
    "Y = df.label.values\n",
    "x, x_test, y, y_test = train_test_split(X, Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "337/337 [==============================] - 102s 304ms/step - loss: 0.5188 - categorical_accuracy: 0.8045\n",
      "Epoch 2/5\n",
      "337/337 [==============================] - 85s 253ms/step - loss: 0.2164 - categorical_accuracy: 0.9252\n",
      "Epoch 3/5\n",
      "337/337 [==============================] - 86s 254ms/step - loss: 0.1517 - categorical_accuracy: 0.9499\n",
      "Epoch 4/5\n",
      "337/337 [==============================] - 86s 254ms/step - loss: 0.1216 - categorical_accuracy: 0.9575\n",
      "Epoch 5/5\n",
      "337/337 [==============================] - 86s 255ms/step - loss: 0.0837 - categorical_accuracy: 0.9729\n",
      "Val loss:0.20173659920692444  | Val accuracy:0.9403234720230103\n",
      "*******************************************************************\n",
      "Epoch 1/5\n",
      "337/337 [==============================] - 85s 253ms/step - loss: 0.5507 - categorical_accuracy: 0.7855\n",
      "Epoch 2/5\n",
      "337/337 [==============================] - 85s 253ms/step - loss: 0.2533 - categorical_accuracy: 0.9173\n",
      "Epoch 3/5\n",
      "337/337 [==============================] - 86s 254ms/step - loss: 0.1672 - categorical_accuracy: 0.9459\n",
      "Epoch 4/5\n",
      "337/337 [==============================] - 86s 254ms/step - loss: 0.1301 - categorical_accuracy: 0.9561\n",
      "Epoch 5/5\n",
      "337/337 [==============================] - 89s 265ms/step - loss: 0.1100 - categorical_accuracy: 0.9635\n",
      "Val loss:0.16673903167247772  | Val accuracy:0.945064127445221\n",
      "*******************************************************************\n",
      "Epoch 1/5\n",
      "337/337 [==============================] - 100s 297ms/step - loss: 0.4644 - categorical_accuracy: 0.8317\n",
      "Epoch 2/5\n",
      "337/337 [==============================] - 160s 476ms/step - loss: 0.2259 - categorical_accuracy: 0.9247\n",
      "Epoch 3/5\n",
      "337/337 [==============================] - 108s 320ms/step - loss: 0.1652 - categorical_accuracy: 0.9446\n",
      "Epoch 4/5\n",
      "337/337 [==============================] - 93s 275ms/step - loss: 0.1259 - categorical_accuracy: 0.9577\n",
      "Epoch 5/5\n",
      "337/337 [==============================] - 89s 264ms/step - loss: 0.0959 - categorical_accuracy: 0.9699\n",
      "Val loss:0.603457510471344  | Val accuracy:0.866108775138855\n",
      "*******************************************************************\n",
      "Epoch 1/5\n",
      "337/337 [==============================] - 87s 258ms/step - loss: 0.5746 - categorical_accuracy: 0.7635\n",
      "Epoch 2/5\n",
      "337/337 [==============================] - 88s 260ms/step - loss: 0.2389 - categorical_accuracy: 0.9201\n",
      "Epoch 3/5\n",
      "337/337 [==============================] - 86s 255ms/step - loss: 0.1659 - categorical_accuracy: 0.9439\n",
      "Epoch 4/5\n",
      "337/337 [==============================] - 87s 259ms/step - loss: 0.1247 - categorical_accuracy: 0.9604\n",
      "Epoch 5/5\n",
      "337/337 [==============================] - 88s 262ms/step - loss: 0.0968 - categorical_accuracy: 0.9692\n",
      "Val loss:0.13932757079601288  | Val accuracy:0.9486750364303589\n",
      "*******************************************************************\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "batch_size = 32\n",
    "loss_list = []\n",
    "categorical_accuracy_list = []\n",
    "\n",
    "for train_index, val_index in kf.split(x, y):\n",
    "    x_train, x_val = x[train_index], x[val_index]\n",
    "    y_train, y_val = pd.get_dummies(y[train_index]).values, pd.get_dummies(y[val_index]).values\n",
    "    \n",
    "    train_batch_generator = BatchGenerator(x_train, y_train, batch_size=batch_size)\n",
    "    val_batch_generator = BatchGenerator(x_val, y_val, batch_size=batch_size)\n",
    "    \n",
    "    model = create_model(filters=[8, 16, 32, 32, 64, 64, 16], learning_rate=0.005, activation=\"relu\")\n",
    "    model.fit(x=train_batch_generator, verbose=1, epochs=5)\n",
    "    loss, categorical_accuracy = model.evaluate(x=val_batch_generator, verbose=0)\n",
    "    \n",
    "    print(\"Val loss:{}  | Val accuracy:{}\".format(loss, categorical_accuracy))\n",
    "    print(\"*******************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 18s 355ms/step - loss: 0.1079 - categorical_accuracy: 0.9617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10785161703824997, 0.961731493473053]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator = BatchGenerator(x_test, pd.get_dummies(y_test).values, batch_size=batch_size)\n",
    "model.evaluate(test_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Rafa\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Rafa\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
